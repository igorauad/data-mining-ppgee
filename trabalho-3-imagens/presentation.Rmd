---
title: "Detecção de pontos em Imagens"
author: 'G4: Edinaldo de Alencar / Igor Freire / Ramon Araújo / Ricardo Ribeiro'
date: "18 de dezembro de 2014"
output:
  slidy_presentation:
    incremental: yes
    footer: "G4: Edinaldo de Alencar / Igor Freire / Ramon Araújo / Ricardo Ribeiro"
  beamer_presentation:
    incremental: yes
bibliography: bibliography.bib
---


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Load dependencies and dataset
#library(doMC)
#registerDoMC()
library(foreach)
load('./matlab/data/data.Rd')
```

## Agenda

1. Problemática
2. Objetivos
3. Fluxo de Trabalho
4. Pré-processamento e transformações
5. Algoritmos
6. Resultados


## Problemática: Detecção de Objetos em Imagens

#### Desafio disponível no *kaggle.com*: "Facial Keypoints Detection''

* Base de treinamento contendo 7049 imagens positivas e suas coordenadas de pontos chaves: Olhos, Sobrancelhas, Nariz e Boca. Também há 3019 imagens negativas
* Base de teste com 1783 imagens

![Base de Imagens Faciais](./figs/gallery.png)

*Dados fornecidos pelo Dr. Yoshua Bengio, da University of Montreal*


## Objetivos

### Identificar e localizar a boca em uma face humana

Dados disponíveis na base:

- $\text{mouth_left_corner}$: canto esquerdo
- $\text{mouth_right_corner}$: canto direito
- $\text{mouth_center_top_lip}$: centro do lábio superior
- $\text{mouth_center_bottom_lip}$: centro do lábio inferior 


### Métrica de Avaliação
- RMSE entre as coordenadas detectadas e verdadeiras


## Fluxo de Trabalho

![Fluxo de Trabalho](./figs/workflow.png)



## Pré-processamento

- Atribuir identificador `NaN` para dados (coordenadas) ausentes
- Converter imagens dadas na base como vetores 'Char' para matrizes `Int8` de dimensões $96 \times 96$
- Para o MATLAB, dividir estas matrizes por 255 e salvar as matrizes resultantes (com elementos no intervalo de 0 a 1) representativas de imagens em *grayscale*
- Detecção de *outliers*:

![Exemplo Outlier](./figs/exemplo_outlier.png)




## Separação de Dados

- Os outliers e as imagens positivas com coordenadas da boca ausentes são descartadas

- As imagens restantes da base de treinamento são separadas em novos conjuntos: 
    - **Treino:** 80% 
    - **Teste:** 20% 

## Extração de *Features* e *Patches*

### *Patches*:
* Subimagens de interesse
* Usado no método de identifição através da correlação

### *Features*:
* Melhor representação do conhecimento em comparação aos pixels puros
* O uso de *features* permite operações muito mais rápidas 
* Haar features (features retangulares) - método de Viola-Jones





## *Baseline* estatístico: Correlação

Patch médio de todas as bocas na base de dados:
```{r, echo=FALSE, message=FALSE}
source('meanPatch.R')
```

#### Lábio superior (*mouth_center_top_lip*)

Definir coordenada:
```{r, cache=TRUE}
coord      <- "mouth_center_top_lip" 
```

Definir dimensão do *patch*:
```{r, cache=TRUE}
patch_size <- 15  # e.x. 10 significaria um quadrado de 21x21 pixels (10+1+10).  
``` 

Calcular *patch* médio:
```{r, cache=TRUE}
mean.patch <- meanPatch(coord, patch_size, TRUE) 
```


#### Lábio inferior (*mouth_center_bottom_lip*)
```{r, cache=TRUE, echo=FALSE}
coord      <- "mouth_center_bottom_lip" 
patch_size <- 15 
mean.patch <- meanPatch(coord, patch_size, TRUE) 
```

#### Canto esquerdo (*mouth_left_corner*)

Observar enantiomorfismo:
```{r, cache=TRUE, echo=FALSE}
coord      <- "mouth_left_corner" 
patch_size <- 15 
mean.patch <- meanPatch(coord, patch_size, TRUE) 
```

#### Canto direito (*mouth_right_corner*)
```{r, cache=TRUE, echo=FALSE}
coord      <- "mouth_right_corner" 
patch_size <- 15 
mean.patch <- meanPatch(coord, patch_size, TRUE) 
```

## Método Correlação - Predição

Ver [@kaggleTutorial]

* Correlação cruzada entre os pixels de *patch* médio e de uma região de busca na imagem
* Região de busca definida como um *grid*, em cujas coordenadas o *patch* médio é centrado iterativamente
* Detecção: coordenadas nas quais encontra-se a maior correlação

![Busca de Patch](./figs/patch_search.png)

```{r, cache=TRUE}
source('predictWithCorrelation.R')
```

Definir intervalo de busca:
```{r, cache=TRUE}
search_size <- 20 # e.g. would give a 5x5 (2+1+2) 
```

#### Lábio superior (*mouth_center_top_lip*)
```{r, echo=FALSE, cache=TRUE, warning=FALSE}
coord      <- "mouth_center_top_lip" 
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patch_size <- 21
mean.patch <- meanPatch(coord, patch_size, FALSE) 
```

```{r}
iImg = 4 # Escolher imagem
# Estimar coordenadas usando correlacao e plotar em vermelho:
estimated_p <- predictWithCorrelation(coord, search_size, mean.patch, iImg, TRUE) 
# Plotar coordenadas reais em verde:
points(96 - d.test[iImg, coord_x], 96 - d.test[iImg, coord_y], col="green")
```

```{r}
# RMSE:
real_p <- c(d.test$mouth_center_top_lip_x[iImg], d.test$mouth_center_top_lip_y[iImg])
err <- estimated_p - real_p
sqrt(mean(err^2))
```

```{r, echo=FALSE, cache=TRUE}
d_mouth_center_top_lip <- estimated_p
```


#### Lábio inferior (*mouth_center_bottom_lip*)
```{r, echo=FALSE, cache=TRUE, warning=FALSE}
coord      <- "mouth_center_bottom_lip" 
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patch_size <- 10
mean.patch <- meanPatch(coord, patch_size, FALSE) 
```

```{r, echo=FALSE, cache=TRUE}
estimated_p <- predictWithCorrelation(coord, search_size, mean.patch, iImg, TRUE) 
# Plotar coordenadas reais em verde:
points(96 - d.test[iImg, coord_x], 96 - d.test[iImg, coord_y], col="green")
```

RMSE:
```{r, echo=FALSE, cache=TRUE}
# Erro:
real_p <- c(d.test$mouth_center_bottom_lip_x[iImg], d.test$mouth_center_bottom_lip_y[iImg])
err <- estimated_p - real_p
sqrt(mean(err^2))
```

```{r, echo=FALSE, cache=TRUE}
d_mouth_center_bottom_lip_x <- estimated_p
```

#### Canto esquerdo (*mouth_left_corner*)
```{r, echo=FALSE, cache=TRUE, warning=FALSE}
coord      <- "mouth_left_corner" 
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patch_size <- 10
mean.patch <- meanPatch(coord, patch_size, FALSE) 
```

```{r, echo=FALSE, cache=TRUE}
estimated_p <- predictWithCorrelation(coord, search_size, mean.patch, iImg, TRUE) 
# Plotar coordenadas reais em verde:
points(96 - d.test[iImg, coord_x], 96 - d.test[iImg, coord_y], col="green")
```

RMSE:
```{r, echo=FALSE, cache=TRUE}
real_p <- c(d.test$mouth_left_corner_x[iImg], d.test$mouth_left_corner_y[iImg])
err <- estimated_p - real_p
sqrt(mean(err^2))
```

```{r, echo=FALSE, cache=TRUE}
d_mouth_left_corner <- estimated_p
```

#### Canto direito (*mouth_right_corner*)
```{r, echo=FALSE, cache=TRUE, warning=FALSE}
coord      <- "mouth_right_corner" 
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patch_size <- 10
mean.patch <- meanPatch(coord, patch_size, FALSE) 
```

```{r, echo=FALSE, cache=TRUE}
estimated_p <- predictWithCorrelation(coord, search_size, mean.patch, iImg, TRUE) 
# Plotar coordenadas reais em verde:
points(96 - d.test[iImg, coord_x], 96 - d.test[iImg, coord_y], col="green")
```

RMSE:
```{r, echo=FALSE, cache=TRUE}
real_p <- c(d.test$mouth_right_corner_x[iImg], d.test$mouth_right_corner_y[iImg])
err <- estimated_p - real_p
sqrt(mean(err^2))
```

```{r, echo=FALSE, cache=TRUE}
d_mouth_right_corner <- estimated_p
```


### Retângulo com detecção:
```{r}
im  <- matrix(data=rev(im.test[iImg,]), nrow=96, ncol=96)
image(1:96, 1:96, im, col=gray((0:255)/255))
xleft <- 96 - d_mouth_left_corner[1]
ybottom <- 96 - d_mouth_center_bottom_lip_x[2]
xright <- 96 - d_mouth_right_corner[1]
ytop <- 96 - d_mouth_center_top_lip[2]

rect(xleft, ybottom, xright, ytop, lwd=2, border="green" );
```




## Método Correlação - Observações

* Acurácia satisfatória
* Para obter os melhores resultados, é necessário otimizar:
    * a dimensão do *patch* 
    * o campo de busca
* **Desvantagem: Custo computacional extremamente elevado**
    * A execução no conjunto de teste demorou ~11 min!




## Sensibilidade do Método de Correlação

### Parâmetros do método de correlação
* Dados de treino

* 1702 imagens positivas

* Janelas de pixels *(patch)* de $11\times 11$, $13\times 13$ a $23\times 23$


### Curvas ROC $(1-SPEC)\times(SENS)$

* Descreve a fração de verdadeiros positivos $(FVP)$ em função da fração de falsos positivos $(FFP)$

* **Sensibilidade:** $$ FVP = \frac{VP}{VP+FN} = \frac{VP}{P} $$


* **Especificidade:** $$ FFP = \frac{FP}{FP+VN} = \frac{FP}{N} $$

* Dados de teste

    * 425 imagens positivas $(P=425)$

    * 1000 imagens negativas $(N=1000)$



## Sensibilidade do Método de Correlação


### Curvas ROC $(1-SPEC)\times(SENS)$

Pesquisa em janelas de pixels de $5\times 5$, $7\times 7$ e $9\times 9$ centradas na média dos pontos-chave das imagens de treino.

Fixando a pesquisa em janelas de pixels de $7\times 7$ e variando o tamanho do *patch*, vem:

<img src="./figs/curvas_roc_patch_(11-por-11).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_patch_(13-por-13).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_patch_(15-por-15).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_patch_(17-por-17).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_patch_(19-por-19).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_patch_(21-por-21).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_patch_(23-por-23).png" height="600px" width="450px" />

Fixando o tamanho do *patch* em janelas de $11\times 11$ pixels e variando a janela de pesquisa, vem:

<img src="./figs/curvas_roc_pesquisa_(5-por-5).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_pesquisa_(7-por-7).png" height="600px" width="450px" />
<img src="./figs/curvas_roc_pesquisa_(9-por-9).png" height="600px" width="450px" />

## Método de Viola-Jones

Ver [@viola_jones_paper2001] [@jones2001robust]

1. Representação Integral e extração de *features* retangulares
2. Construção de classificadores através da seleção de Features com AdaBoost
3. Cascateamento de classificadores

* Treinamento dos classificadores é extremamente longo, mas a detecção passa a ser muito rápida
    * Segundo [@viola_jones_paper2001], para imagens 384 x 288 e utilizando processador 700MHz, este algoritmo detecta faces a uma taxa de 15 imagens por segundo
    
    
## *Features* retangulares

* Reminescentes das funções base de *wavelets* Haar
* Captura de padrões em orientação horizontal, vertical e diagonal

![Haar Features](./figs/haar_features.jpg)

### Tipos
* **(A e B)** - "dois-retângulos": valor é a diferença entre a soma dos pixels de cada um dos retângulos 
$$ \text{feature} = (\text{soma ret. branco}) - (\text{soma ret. preto}) $$
* **(C)** - "três-retângulos" : soma dos pixels nos dois retângulos externos subtraída da soma dos pixels no retângulo interno
$$ \text{feature} = (\text{soma rets. brancos}) - (\text{soma ret. preto}) $$
* **(D)** - "quatro-retângulos": diferença entre as somas dos pixels dos pares de retângulos diagonais
$$ \text{feature} = (\text{soma rets. brancos}) - (\text{soma rets. pretos}) $$

## Representação Imagem Integral
* Uma das três contribuições principais do trabalho de Viola-Jones
* Valor em $(x, y)$ corresponde à soma de todos os pixels acima e à esquerda de $(x, y)$, inclusive

![imagem_integral](./figs/imagem_integral.png)

* Há recorrência:
    * Exemplo: valor em $(x+1, y)$ é dado pelo valor em $(x, y)$ acrescido do valor na representação original em $(x+1, y)$
* É possível calcular a representação integral com uma única "passada" na imagem 
* A partir da representação integral pode-se: 
    1. calcular a soma dos valores dos pixels em um retângulo a partir de 4 referências (os cantos);
    2. a diferença entre a soma de dois retângulos a partir de 8 referências
* Ferramenta poderosa pra calcular os *features* retangulares com baixo custo computacional 



#### Número de referências para cada *Feature*
* Tipo "dois-retângulos": 6 (reduz-se de 8 pra 6 devido ao fato de serem adjacentes)
* Tipo "três-retângulos": 8
* Tipo "quatro-retângulos": 9

**Nota**: custo computacional para calcular um *feature* é baixo, mas o número de *features* possíveis em uma imagem é extremamente elevado
    
    * Uma imagem 24 x 24 possui mais de 160 mil features!    

## Construção de classificadores
* A utilização  de todo o conjunto de *features* é proibitiva    
* Objetivo: combinar um número pequeno de *features* para formar um classificador efetivo
* *AdaBoost*: usado para selecionar um pequeno número de *features*
* *Weak learners*: classificadores simples
* *Boosting*: treinamento de um classificador (*strong*) com alta acurácia a partir da combinação linear das decisões feitas por *weak learners* $$f = \alpha_0 f_0 + \alpha_1 f_1 + \cdots + \alpha_N f_N$$

## *Strong Classifiers* em cascata
* Formado por estágios
* Cada estágio é composto por um conjunto de *weak learners*
* Cada *strong classifier* é treinado somente a partir das amostras que passam dos classificadores precedentes
* Sub-janelas são inspecionadas, passando pelos estágios do classificador em cascata
* Classificações:
    * **Negativa**: processamento se encerra e a próxima sub-janela passa a ser inspecionada
    * **Positiva**: sub-janela continua a ser processada pelo próximo estágio do classificador
* Falsos-positivos são aceitáveis, enquanto falsos-negativos devem ocorrer a uma taxa próxima de 0%
* **Taxa global de falsos-positivos e de detecção**: dadas pelo produto das respectivas taxas individuais ($f_k$) de cada um dos $M$ estágios $$ f = \prod \limits_{k=0}^{M-1} f_k$$
* Estágios com performances individuais ruins podem atingir uma performance global satisfatória (*e.g.* 60% x 60% = 36%)
* Para uma taxa global de detecção (verdadeiro-positivo) tão próxima quando possível de 100%, os estágios precisam ter performances individuais igualmente próximas de 100%

## Treinando um Classificador

* Classificadores pré-treinados em `vision.CascadeObjectDetector` (MATLAB)
* Viola-Jones é preferível para objetos cuja razão de aspecto não varia significativamente
* Necessário conjunto de imagens positivas e negativas
* Objeto encontrado em uma imagem negativa (falso-positivo): será passado como imagem negativa para o treinamento do próximo estágio do classificador 
* Amostra positiva classificada erroneamente como negativa (falso-negativo): é descartada, isto é, não é usada no treinamento dos estágios seguintes
* Amostras positivas podem se esgotar antes que todos os estágios estejam treinados

![cascadeTraining](./figs/cascadeTraining.png)

### Relações de compromisso:
* **Mais estágios**:
    * Melhora taxa de falsos-positivos
    * Piora taxa de verdadeiros-positivos
    * Piora taxa de falsos-negativos (mais estágios, maior probabilidade de rejeição)
    * Necessita de mais imagens negativas para treinamento (somente falsos-positivos são passados como imagens negativas aos estágios seguintes)

### Práticas
* Como a base de dados é relativamente grande, pode-se aumentar o número de estágios e relaxar (aumentar) as especificações de taxa de falsos-positivos em cada estágio (menos *weak learners* em cada estágio)
* Para economizar tempo, tunar os parâmetros usando *features* LBP ou HOG
* Geração de amostras positivas a partir de rotações, adição de ruído ou mudança de contraste
* Utilizar imagens negativas com fundos e cenários semelhantes às imagens positivas
* Melhorar o contraste das imagens por meio da função `imadjust`

<!--
![Reconhecimento com Correlacao](./figs/correlacao_comparacao.png)

![Reconhecimento com Correlacao](./figs/correlacao_comparacao2.png)
-->





## Viola-Jones: Detectores no MATLAB

<!--
* Detecção com coordenadas Y mais baixas é a escolhida 
-->

* A toolbox `Computer Vision` do MATLAB contém um classificador de reconhecimento de faces, invocado por `vision.CascadeObjectDetector('Mouth')`

* É possível também treinar um classificador por meio da função $$ \begin{aligned} \text{trainCascadeObjectDetector}&\text{(outputXML, positiveData, negativeData,} \\ &\text{'FalseAlarmRate', FAR} \\ &\text{'TruePositiveRate', TPR,} \\ &\text{'NumCascadeStages', numStages,} \\ &\text{'FeatureType', 'Haar',} \\ & \text{'ObjectTrainingSize', [height width])} \end{aligned} $$


* Detectores Utilizados nos Testes:

1. Classificador da toolbox `Computer Vision` do MATLAB
2. Classificador treinado com 5 estágios, $FAR=0.2$, $TPR=0.995$ e FeatureType = Haar
3. Classificador treinado com 7 estágios, $FAR=0.2$, $TPR=0.995$ e FeatureType = Haar


## Viola-Jones: Detecção de bocas no MATLAB


* Os detectores retornam os *bounding boxes* de todos os pontos-chave (olhos, nariz e boca) da face. O retângulo relativo à boca é escolhido como aquele com as maiores coordenadas y

![Reconhecimento com Viola-Jones](./figs/violaJones_comparacao.png)


* A partir do *bounding box* da boca, são estimadas as posições dos cantos esquerdo e direito da boca, e os centros dos lábios inferior e superior.

![localizacao_pontos_base_viola_jones](./figs/comparacao_pontos_boca_ViolaJones.png)



## Viola-Jones: Resultados

### Matrizes de Confusão

<!--
* Detector disponível no *toolbox Computer Vision* no MATLAB: $$ \text{Taxa de verdadeiro positivo} = 93.94 \% \\ \text{Taxa de falso negativo} = 6.06 \% $$

* Classificador treinado de $5$ estágios: $$ \text{Taxa de verdadeiro positivo} = 77.46 \% \\ \text{Taxa de falso negativo} = 22.53 \% $$

* Classificador treinado de $8$ estágios: $$ \text{Taxa de verdadeiro positivo} = 57.51 \% \\ \text{Taxa de falso negativo} = 42.49 \% $$
-->


![confusion matrices](./figs/confusion_matrices.png)


* Exemplo de imagem falso positivo:

![False Positive](./figs/falsePositive_violaJones.png)




## Acurácia - Viola-Jones x Correlação



* Primeiramente, toma-se o erro médio quadrático (RMSE), de forma independente, das distâncias entre o ponto real e detectado de cada uma das 4 coordenadas da boca

* O RMSE geral é a média aritmética entre os 4 RMSEs acima


![RMSEs](./figs/RMSEs.png)



<!--
* Detector disponível no *toolbox Computer Vision* no MATLAB: $$\text{RMSE(canto esquerdo)} = 2.7634 \\ \text{RMSE(lábio inferior)} = 3.0972 \\ \text{RMSE(canto direito)} = 2.5832 \\ \text{RMSE(lábio superior)} = 2.4417 \\ \text{RMSE} = 2.7214$$


* Classificador treinado de $5$ estágios: $$\text{RMSE(canto esquerdo)} = 3.9085 \\ \text{RMSE(lábio inferior)} = 3.4108 \\ \text{RMSE(canto direito)} = 3.9426 \\ \text{RMSE(lábio superior)} = 3.8654 \\ \text{RMSE} = 3.7818$$

* Classificador treinado de $8$ estágios: $$\text{RMSE(canto esquerdo)} = 4.0883 \\ \text{RMSE(lábio inferior)} = 3.6187 \\ \text{RMSE(canto direito)} = 4.1387 \\ \text{RMSE(lábio superior)} = 4.148 \\ \text{RMSE} = 3.9984$$
-->





## Referências




